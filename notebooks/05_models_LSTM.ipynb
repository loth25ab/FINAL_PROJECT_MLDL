{"cells":[{"cell_type":"markdown","metadata":{"id":"gISMzJnmqbPB"},"source":["# Notebook 05 — LSTM Experiments (Full Dataset)\n","\n","In this step, we explore a **sequence-based deep learning approach** using an LSTM model trained on the **full `eurusd_features_with_regimes` dataset**.  \n","Unlike per-regime modeling, this notebook ignores regime splits and feeds the model the entire engineered feature set.\n","\n","**Objectives:**\n","1. Prepare time-ordered feature data with next-day direction targets.\n","2. Convert features into fixed-length rolling sequences (no data leakage).\n","3. Perform **rolling time-series cross-validation** with an LSTM:\n","   - Leakage-safe scaling (fit only on train folds)\n","   - Early stopping and class weights for imbalance\n","4. Evaluate **out-of-fold performance** across folds.\n","5. Train a **final full-dataset LSTM model** for downstream backtesting.\n","6. Export:\n","   - OOF predictions (`*_lstm_full_oof.parquet`)\n","   - SavedModel (`*_lstm_full_savedmodel/`)\n","   - Associated scaler (`*_lstm_full_scaler.joblib`)"]},{"cell_type":"markdown","metadata":{"id":"5P3WwRTsqkEu"},"source":["## Setup + project paths"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":788,"status":"ok","timestamp":1754966232882,"user":{"displayName":"Lou-Félix","userId":"04182805383147980959"},"user_tz":240},"id":"0iSfcTVIqU9E","outputId":"a2542de0-72f4-439d-c965-3a49880de2b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","PROJECT_ROOT: /content/drive/MyDrive/FINAL_PROJECT_MLDL\n","/content/drive/MyDrive/FINAL_PROJECT_MLDL\n","SRC_DIR on sys.path: True\n","PROC_DIR: /content/drive/MyDrive/FINAL_PROJECT_MLDL/data/processed\n"]}],"source":["\n","import os, sys, json\n","from pathlib import Path\n","\n","# Detect Colab\n","IN_COLAB = False\n","try:\n","    import google.colab  # type: ignore\n","    IN_COLAB = True\n","except Exception:\n","    IN_COLAB = False\n","\n","# Mount Drive & set PROJECT_ROOT\n","if IN_COLAB:\n","    from google.colab import drive  # type: ignore\n","    drive.mount('/content/drive')\n","    PROJECT_ROOT = Path(\"/content/drive/MyDrive/FINAL_PROJECT_MLDL\")\n","else:\n","    PROJECT_ROOT = Path(\".\").resolve()\n","\n","PROJECT_ROOT.mkdir(parents=True, exist_ok=True)\n","print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n","\n","%cd \"$PROJECT_ROOT\"\n","\n","# Ensure src is importable\n","SRC_DIR = PROJECT_ROOT / \"src\"\n","if str(SRC_DIR) not in sys.path:\n","    sys.path.insert(0, str(SRC_DIR))\n","print(\"SRC_DIR on sys.path:\", str(SRC_DIR) in sys.path or str(SRC_DIR) == sys.path[0])\n","\n","# Folders\n","CFG_DIR  = PROJECT_ROOT / \"config\"\n","DATA_DIR = PROJECT_ROOT / \"data\"\n","PROC_DIR = DATA_DIR / \"processed\"\n","PROC_DIR.mkdir(parents=True, exist_ok=True)\n","print(\"PROC_DIR:\", PROC_DIR)\n","\n","# Select Asset\n","ASSET_KEY = \"eurusd\"\n","\n","# Colab deps (idempotent)\n","if IN_COLAB:\n","    try:\n","        import pyarrow, sklearn, yaml  # noqa: F401\n","    except Exception:\n","        !pip -q install pyarrow scikit-learn pyyaml\n"]},{"cell_type":"markdown","metadata":{"id":"uCR6S0qZq1kP"},"source":["## Imports"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1754966232884,"user":{"displayName":"Lou-Félix","userId":"04182805383147980959"},"user_tz":240},"id":"O7v263VXq1WV"},"outputs":[],"source":["\n","import os, json, re, glob, warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n"]},{"cell_type":"markdown","metadata":{"id":"mocUo6BIq_TB"},"source":["## Load data"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4337,"status":"ok","timestamp":1754966237216,"user":{"displayName":"Lou-Félix","userId":"04182805383147980959"},"user_tz":240},"id":"41HVi-_Dq_K2"},"outputs":[],"source":["\n","def asset_file(stem: str) -> Path:\n","    \"\"\"Convenience path for processed files of the current asset.\"\"\"\n","    return PROC_DIR / f\"{ASSET_KEY}_{stem}.parquet\"\n","\n","# Build X/y using PRUNED feature sets to reduce noise\n","features = pd.read_parquet(asset_file(\"features_with_regimes\")).sort_values(\"Date\").reset_index(drop=True)\n","\n","# Target\n","aligned = pd.read_parquet(asset_file(\"aligned\")).sort_values(\"Date\").reset_index(drop=True)\n","tgt_close_cols = [c for c in aligned.columns if isinstance(c, str) and c.startswith(\"target_\") and c.endswith(\"_Close\")]\n","if not tgt_close_cols:\n","    tgt_close_cols = [c for c in aligned.columns if c == \"target_Close\"]\n","assert tgt_close_cols, \"target close not found\"\n","tgt_col = tgt_close_cols[0]\n","\n","aligned[\"ret1\"]   = aligned[tgt_col].pct_change()\n","aligned[\"y_next\"] = np.sign(aligned[\"ret1\"].shift(-1)).replace({-1:0, 1:1}).astype(\"Int64\")\n","y_frame = aligned[[\"Date\",\"y_next\"]].dropna()\n","\n","# Merge & sort\n","df = (features.merge(y_frame, on=\"Date\", how=\"inner\")\n","               .dropna(subset=[\"y_next\"])\n","               .sort_values(\"Date\")\n","               .reset_index(drop=True))\n"]},{"cell_type":"markdown","metadata":{"id":"3Hwkvdj8ydWm"},"source":["## Pruned Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"BTDLo_mPz53u"},"source":["We load the **features_with_regimes** dataset and merge it with the aligned price data to create the next-day direction target (`y_next`).  \n","To reduce noise and improve model focus, we use the **union of pruned features** from the Random Forest feature selection step (`*_rf_kept_features.json`).  \n","If no pruning file is found, all numeric features are used."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":945,"status":"ok","timestamp":1754966238163,"user":{"displayName":"Lou-Félix","userId":"04182805383147980959"},"user_tz":240},"id":"nO4MW-JOydJS","outputId":"144c7741-d351-4af4-d228-5f6ec87ebb42"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using pruned feature union: 51 columns.\n","Final X shape: (3851, 51) | features: ['regime_id', 'bench_ma10', 'bench_ma5', 'bench_ret1', 'bench_ret5', 'bench_ret60', 'corr_bench_20', 'corr_bench_60'] ...\n"]}],"source":["\n","# Load kept features per-regime and take the UNION (fallback to all numeric if file missing)\n","kept_path = PROC_DIR / f\"{ASSET_KEY}_rf_kept_features.json\"\n","if kept_path.exists():\n","    kept_by_regime = json.loads(kept_path.read_text())\n","    kept_union = sorted({c for cols in kept_by_regime.values() for c in cols})\n","    # Keep only those present in df; also keep regime_id (numeric) if available\n","    pruned_cols = [c for c in kept_union if c in df.columns]\n","    if \"regime_id\" in df.columns:\n","        pruned_cols = [\"regime_id\"] + pruned_cols\n","    print(f\"Using pruned feature union: {len(pruned_cols)} columns.\")\n","else:\n","    print(\"Kept-features JSON not found — using all numeric columns.\")\n","    pruned_cols = None\n","\n","y = df[\"y_next\"].astype(int).values\n","if pruned_cols:\n","    X = df[pruned_cols].select_dtypes(include=[np.number])\n","else:\n","    X = df.drop(columns=[\"Date\",\"y_next\"]).select_dtypes(include=[np.number])\n","\n","print(\"Final X shape:\", X.shape, \"| features:\", X.columns[:8].tolist(), \"...\")\n"]},{"cell_type":"markdown","metadata":{"id":"ozlYJSSKrN_x"},"source":["## Sequence helpers (no leakage)"]},{"cell_type":"markdown","metadata":{"id":"pcvZM8W50B7d"},"source":["We define:\n","- **Two LSTM layers** (64 → 32 units) with dropout in between to capture deeper temporal dependencies.\n","- **L2 weight decay** on both recurrent and dense layers to reduce overfitting.\n","- **Longer sequence window (60 timesteps)** to allow better pattern learning.\n","- Positive class **weight boost** to improve recall.\n","- **ReduceLROnPlateau** learning rate schedule for smoother convergence."]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1754966238180,"user":{"displayName":"Lou-Félix","userId":"04182805383147980959"},"user_tz":240},"id":"DT6hF-AOrNzK"},"outputs":[],"source":["\n","from tensorflow.keras import layers, regularizers, callbacks, optimizers\n","\n","LSTM_WIN = 60          # longer sequence\n","EPOCHS   = 80\n","BATCH    = 32          # smaller batch for better minima\n","PATIENCE = 15          # more patience (noisy finance CV)\n","L2      = 1e-4         # weight decay\n","\n","def make_sequences(X_df, y_arr, win=LSTM_WIN):\n","    X_np = X_df.values.astype(\"float32\")\n","    y_np = y_arr.astype(\"float32\")\n","    n = len(X_np)\n","    if n <= win:\n","        return np.empty((0, win, X_np.shape[1]), \"float32\"), np.empty((0,), \"float32\"), np.array([], int)\n","    Xs, ys, idxs = [], [], []\n","    for t in range(win, n):\n","        Xs.append(X_np[t-win:t])\n","        ys.append(y_np[t])\n","        idxs.append(t)\n","    return np.stack(Xs), np.array(ys), np.array(idxs)\n","\n","def class_weights_binary(y_vec, pos_boost=1.5):\n","    pos = (y_vec == 1).sum()\n","    neg = (y_vec == 0).sum()\n","    if pos == 0 or neg == 0:\n","        return {0:1.0, 1:1.0}\n","    tot = pos + neg\n","    base = {0: tot/(2.0*neg), 1: tot/(2.0*pos)}\n","    base[1] *= pos_boost  # ↑ positive weight to help recall\n","    return base\n","\n","def build_lstm_model(n_features, units=(64, 32), dropout=(0.3, 0.3), l2=L2):\n","    inp = layers.Input(shape=(None, n_features))\n","    x = layers.LSTM(units[0], return_sequences=True,\n","                    kernel_regularizer=regularizers.l2(l2),\n","                    recurrent_regularizer=regularizers.l2(l2))(inp)\n","    x = layers.Dropout(dropout[0])(x)\n","    x = layers.LSTM(units[1],\n","                    kernel_regularizer=regularizers.l2(l2),\n","                    recurrent_regularizer=regularizers.l2(l2))(x)\n","    x = layers.Dropout(dropout[1])(x)\n","    x = layers.Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(l2))(x)\n","    out = layers.Dense(1, activation=\"sigmoid\")(x)\n","\n","    # LR schedule: ReduceLROnPlateau (cosine alternative shown below)\n","    opt = optimizers.Adam(learning_rate=1e-3)\n","    model = tf.keras.Model(inp, out)\n","    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.AUC(name=\"auc\")])\n","    return model\n","\n","def eval_class(y_true, prob):\n","    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","    pred = (prob >= 0.5).astype(int)\n","    out = {\"acc\":accuracy_score(y_true,pred),\n","           \"prec\":precision_score(y_true,pred,zero_division=0),\n","           \"rec\":recall_score(y_true,pred,zero_division=0),\n","           \"f1\":f1_score(y_true,pred,zero_division=0)}\n","    out[\"auc\"] = roc_auc_score(y_true, prob) if len(np.unique(y_true))>1 else np.nan\n","    return out\n"]},{"cell_type":"markdown","metadata":{"id":"rnoA-xRXrVxZ"},"source":["## Rolling TimeSeries CV (leakage-safe scaling + sequence CV)"]},{"cell_type":"markdown","metadata":{"id":"E96BrVOB0Knx"},"source":["We apply **5-fold rolling TimeSeriesSplit** to avoid lookahead bias.  \n","Steps per fold:\n","1. **Standard scaling** on training only.\n","2. Convert data to fixed-length sequences (`win=60`).\n","3. Train the stacked LSTM with **class weights** and **early stopping** (patience=15).\n","4. Use **smaller batch size (32)** for better minima exploration.\n","5. Record out-of-fold predictions and evaluate metrics: accuracy, precision, recall, F1, and AUC."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"-dOanQ3drVmO","executionInfo":{"status":"ok","timestamp":1754966355283,"user_tz":240,"elapsed":117101,"user":{"displayName":"Lou-Félix","userId":"04182805383147980959"}},"outputId":"53e10d22-f6a0-4dcc-c03b-bf90c2cd01b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Fold 1] acc:0.499 | prec:0.501 | rec:0.993 | f1:0.666 | auc:0.500\n","[Fold 2] acc:0.561 | prec:0.526 | rec:0.809 | f1:0.637 | auc:0.587\n","[Fold 3] acc:0.508 | prec:0.508 | rec:1.000 | f1:0.674 | auc:0.509\n","[Fold 4] acc:0.485 | prec:0.486 | rec:0.919 | f1:0.636 | auc:0.493\n","[Fold 5] acc:0.487 | prec:0.487 | rec:1.000 | f1:0.655 | auc:0.546\n","\n","OOF mean across folds:\n"]},{"output_type":"display_data","data":{"text/plain":["      fold    acc   prec    rec     f1    auc\n","mean   3.0  0.508  0.502  0.944  0.654  0.527"],"text/html":["\n","  <div id=\"df-9dab195d-379f-4fca-a584-2bb5922646bd\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fold</th>\n","      <th>acc</th>\n","      <th>prec</th>\n","      <th>rec</th>\n","      <th>f1</th>\n","      <th>auc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>mean</th>\n","      <td>3.0</td>\n","      <td>0.508</td>\n","      <td>0.502</td>\n","      <td>0.944</td>\n","      <td>0.654</td>\n","      <td>0.527</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dab195d-379f-4fca-a584-2bb5922646bd')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9dab195d-379f-4fca-a584-2bb5922646bd button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9dab195d-379f-4fca-a584-2bb5922646bd');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(fold_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"fold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.508,\n        \"max\": 0.508,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.508\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.502,\n        \"max\": 0.502,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.502\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.944,\n        \"max\": 0.944,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.654,\n        \"max\": 0.654,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.527,\n        \"max\": 0.527,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.527\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["\n","N_SPLITS = 5\n","tscv = TimeSeriesSplit(n_splits=N_SPLITS)\n","\n","oof_prob = np.full(len(df), np.nan, dtype=float)\n","fold_metrics = []\n","\n","for fold, (tr_idx, va_idx) in enumerate(tscv.split(X), start=1):\n","    X_tr_raw, X_va_raw = X.iloc[tr_idx], X.iloc[va_idx]\n","    y_tr, y_va = y[tr_idx], y[va_idx]\n","\n","    # Scale on TRAIN only\n","    scaler = StandardScaler()\n","    X_tr = pd.DataFrame(scaler.fit_transform(X_tr_raw), index=X_tr_raw.index, columns=X.columns)\n","    X_va = pd.DataFrame(scaler.transform(X_va_raw),    index=X_va_raw.index, columns=X.columns)\n","\n","    # Sequences\n","    Xtr_seq, ytr_seq, idx_tr_seq = make_sequences(X_tr, y_tr, win=LSTM_WIN)\n","    Xva_seq, yva_seq, idx_va_seq = make_sequences(X_va, y_va, win=LSTM_WIN)\n","    if len(idx_tr_seq)==0 or len(idx_va_seq)==0:\n","        print(f\"[Fold {fold}] Not enough sequence data — skipping.\")\n","        continue\n","\n","    model = build_lstm_model(n_features=X.shape[1])\n","    cw = class_weights_binary(ytr_seq, pos_boost=1.7)  # a bit stronger than default 1.5\n","\n","    cbs = [\n","        callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=PATIENCE, restore_best_weights=True),\n","        callbacks.ReduceLROnPlateau(monitor=\"val_auc\", mode=\"max\", factor=0.5, patience=6, min_lr=1e-5)\n","    ]\n","\n","    model.fit(\n","        Xtr_seq, ytr_seq,\n","        validation_data=(Xva_seq, yva_seq),\n","        epochs=EPOCHS,\n","        batch_size=BATCH,\n","        class_weight=cw,\n","        verbose=0,\n","        callbacks=cbs\n","    )\n","\n","    pva = model.predict(Xva_seq, verbose=0).reshape(-1)\n","    df_va_rows = X_va.index[idx_va_seq]\n","    oof_prob[df_va_rows] = pva\n","\n","    m = eval_class(y[df_va_rows].astype(int), oof_prob[df_va_rows])\n","    fold_metrics.append({\"fold\": fold, **m})\n","    print(f\"[Fold {fold}] \" + \" | \".join(f\"{k}:{v:.3f}\" for k,v in m.items()))\n","\n","fold_df = pd.DataFrame(fold_metrics)\n","print(\"\\nOOF mean across folds:\")\n","display(fold_df.mean(numeric_only=True).to_frame(\"mean\").T.round(3))\n"]},{"cell_type":"markdown","metadata":{"id":"sHH2s2c5rdi0"},"source":["## Save OOF & Train Full Model (for inference/backtests)"]},{"cell_type":"markdown","metadata":{"id":"Xv1xXeJh0P17"},"source":["After cross-validation, we refit the LSTM on the full dataset using the same architecture and hyperparameters.  \n","We save:\n","- Trained LSTM model.\n","- Out-of-fold probabilities.\n","- Predictions and signals for backtesting."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RYq35rtWrdYZ","executionInfo":{"status":"ok","timestamp":1754966468725,"user_tz":240,"elapsed":113426,"user":{"displayName":"Lou-Félix","userId":"04182805383147980959"}},"outputId":"88c47bbb-0995-4614-95b2-de2ba6c5840a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saved: eurusd_lstm_full_oof.parquet\n","Saved model → /content/drive/MyDrive/FINAL_PROJECT_MLDL/data/processed/eurusd_lstm_full_savedmodel.keras\n","Saved scaler → eurusd_lstm_full_scaler.joblib\n"]}],"source":["# Save OOF predictions (probabilities aligned by Date)\n","oof_out = pd.DataFrame({\"Date\": df[\"Date\"], \"prob_up_oof\": oof_prob})\n","oof_out.to_parquet(asset_file(\"lstm_full_oof\"), index=False)\n","print(\"Saved:\", asset_file(\"lstm_full_oof\").name)\n","\n","# Train a final model on the entire (scaled + sequenced) dataset\n","# 1) Scale on FULL data (for deployment; OOF above already handled CV properly)\n","scaler_full = StandardScaler()\n","X_full = pd.DataFrame(scaler_full.fit_transform(X), index=X.index, columns=X.columns)\n","X_seq, y_seq, idx_seq = make_sequences(X_full, y, win=LSTM_WIN)\n","\n","if len(idx_seq) == 0:\n","    print(\"Not enough rows for full fit sequences — skipping final model save.\")\n","else:\n","    model_full = build_lstm_model(n_features=X.shape[1], units=(64, 32), dropout=(0.2, 0.2)) # Corrected dropout\n","    cw_full = class_weights_binary(y_seq)\n","    cbs_full = [\n","        keras.callbacks.EarlyStopping(monitor=\"auc\", mode=\"max\", patience=10, restore_best_weights=True),\n","        keras.callbacks.ReduceLROnPlateau(monitor=\"auc\", mode=\"max\", factor=0.5, patience=5, min_lr=1e-5)\n","    ]\n","    # We don't have a validation set here; train with class weights and an AUC monitor on training\n","    hist_full = model_full.fit(\n","        X_seq, y_seq,\n","        epochs=80,\n","        batch_size=BATCH,\n","        class_weight=cw_full,\n","        verbose=0,\n","        callbacks=cbs_full\n","    )\n","\n","    # Save model + scaler to disk (scaler needed to reproduce preprocessing)\n","    save_dir = PROC_DIR / f\"{ASSET_KEY}_lstm_full_savedmodel.keras\" # Added .keras extension\n","    keras.models.save_model(model_full, save_dir, overwrite=True)\n","    # Save scaler\n","    import joblib\n","    joblib.dump(scaler_full, PROC_DIR / f\"{ASSET_KEY}_lstm_full_scaler.joblib\")\n","\n","    print(\"Saved model →\", save_dir)\n","    print(\"Saved scaler →\", (PROC_DIR / f\"{ASSET_KEY}_lstm_full_scaler.joblib\").name)"]},{"cell_type":"markdown","metadata":{"id":"kAyPQB--rlBs"},"source":["## Quick performance snapshot"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8FfN0fE6rk1a","executionInfo":{"status":"ok","timestamp":1754966468741,"user_tz":240,"elapsed":13,"user":{"displayName":"Lou-Félix","userId":"04182805383147980959"}},"outputId":"a780e59a-223a-4928-d64c-b24e465e9a94"},"outputs":[{"output_type":"stream","name":"stdout","text":["OOF performance (overall):\n","   acc: 0.508\n","  prec: 0.500\n","   rec: 0.945\n","    f1: 0.654\n","   auc: 0.522\n"]}],"source":["\n","mask = ~np.isnan(oof_prob)\n","if mask.sum() > 0:\n","    overall = eval_class(y[mask].astype(int), oof_prob[mask])\n","    print(\"OOF performance (overall):\")\n","    for k, v in overall.items():\n","        print(f\"  {k:>4}: {v:.3f}\")\n","else:\n","    print(\"No valid OOF predictions to summarize.\")\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOzPfCzEhRZSQqSbH9SqVl+"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}